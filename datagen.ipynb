{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import yaml\n",
    "import itertools\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from yolov2.utils.painter import draw_boxes\n",
    "from yolov2.utils.parser import parse_inputs, parse_label_map\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_path ='../pascal/training_data.csv'\n",
    "config_file   = 'config.yml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config_file, 'r') as stream:\n",
    "    config = yaml.load(stream)\n",
    "    \n",
    "anchors = np.array(config['anchors']) * (config['model']['image_size'] / 608.)\n",
    "\n",
    "num_anchors = config['model']['num_anchors']\n",
    "upper_pts = anchors - anchors / 2.0\n",
    "lower_pts = anchors + anchors / 2.0\n",
    "\n",
    "# for generating ground truth laters\n",
    "anchors_boxes = np.concatenate([upper_pts, lower_pts], axis=-1).astype(np.float32)[[1, 0, 3, 2]]\n",
    "print(anchors_boxes)\n",
    "\n",
    "num_classes = 20\n",
    "shrink_factor = config['model']['shrink_factor']\n",
    "\n",
    "\n",
    "label_dict = parse_label_map(config['label_map'])\n",
    "inv_map = {v: k for k, v in label_dict.iteritems()}\n",
    "inputs, labels = parse_inputs(training_path, inv_map)\n",
    "\n",
    "\n",
    "# Create 10-fold split\n",
    "x_train, x_val = train_test_split(inputs, test_size=0.2)\n",
    "y_train = [labels[k] for k in x_train]\n",
    "y_val   = [labels[k] for k in x_val]\n",
    "\n",
    "print(\"Number of training samples: {} || {}\".format(len(x_train), len(y_train)))\n",
    "print(\"Number of validation samples: {} || {}\".format(len(x_val), len(y_val)))\n",
    "print(\"Anchors:\\n {}\".format(anchors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iou(boxes_list1, boxes_list2, scope=None):\n",
    "    with tf.name_scope(scope, 'IOU'):\n",
    "        areas1        = area(boxes_list1)\n",
    "        areas2        = area(boxes_list2)\n",
    "        intersections = intersection(boxes_list1, boxes_list2)\n",
    "\n",
    "        unions = (tf.expand_dims(areas1, 1) +\n",
    "                  tf.expand_dims(areas2, 0) - intersections)\n",
    "\n",
    "    return tf.where(tf.equal(intersections, 0.0),\n",
    "                    tf.zeros_like(intersections),\n",
    "                    tf.truediv(intersections, unions))\n",
    "\n",
    "\n",
    "def area(boxes, scope=None):\n",
    "    with tf.name_scope(scope, 'Area'):\n",
    "        y_min, x_min, y_max, x_max = tf.split(value=boxes, num_or_size_splits=4, axis=-1)\n",
    "        return tf.squeeze((y_max - y_min) * (x_max - x_min), [1])\n",
    "\n",
    "\n",
    "def intersection(boxes_list1, boxes_list2, scope=None):\n",
    "    with tf.name_scope(scope, 'Intersection'):\n",
    "        y_min1, x_min1, y_max1, x_max1 = tf.split(value=boxes_list1, num_or_size_splits=4, axis=-1)\n",
    "        y_min2, x_min2, y_max2, x_max2 = tf.split(value=boxes_list2, num_or_size_splits=4, axis=-1)\n",
    "\n",
    "        all_pairs_min_ymax = tf.minimum(y_max1, tf.transpose(y_max2))\n",
    "        all_pairs_max_ymin = tf.maximum(y_min1, tf.transpose(y_min2))\n",
    "\n",
    "        intersect_heights = tf.maximum(0.0, all_pairs_min_ymax - all_pairs_max_ymin)\n",
    "        all_pairs_min_xmax = tf.minimum(x_max1, tf.transpose(x_max2))\n",
    "        all_pairs_max_xmin = tf.maximum(x_min1, tf.transpose(x_min2))\n",
    "\n",
    "        intersect_widths = tf.maximum(0.0, all_pairs_min_xmax - all_pairs_max_xmin)\n",
    "\n",
    "    return intersect_heights * intersect_widths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_generator(images, labels, img_size, shuffle=True, batch_size=4):\n",
    "    dataset   = create_tfdata(images, labels, img_size, shuffle, batch_size)\n",
    "    iterator   = dataset.make_one_shot_iterator()\n",
    "    next_batch = iterator.get_next()\n",
    "    while True:\n",
    "        yield K.get_session().run(next_batch)\n",
    "\n",
    "def create_tfdata(images, labels, img_size, shuffle=True, batch_size=4):\n",
    "    \n",
    "    def read_img_file(filename, label):\n",
    "        image = cv2.cvtColor(cv2.imread(filename), cv2.COLOR_BGR2RGB)\n",
    "        height, width, _ = image.shape\n",
    "        image  = cv2.resize(image, (img_size, img_size))\n",
    "        \n",
    "        # A label is consist of [y1, x1, y1, x1, class_idx]\n",
    "        label  = np.reshape(label, (-1, 5))\n",
    "   \n",
    "        # Convert coordinates to relative values\n",
    "        boxes  = label[..., 0:4] / np.array([height, width , height , width], np.float32)\n",
    "        \n",
    "        # Adjust boxes to correct ratio (due to distorted image)\n",
    "        w_ratio = width / float(height)  if width < height else 1.0\n",
    "        h_ratio = height / float(width)  if width < height else 1.0 \n",
    "        boxes   = boxes * np.array([h_ratio, w_ratio, h_ratio, w_ratio], np.float32)\n",
    "        \n",
    "        label  = np.concatenate([boxes, np.expand_dims(label[...,-1],1)], axis=-1)\n",
    "        return image, label\n",
    "\n",
    "    def process_label(img, label):\n",
    "        \n",
    "        # Generate feature map using scater_nd\n",
    "        boxes, classes = tf.split(label, [4, 1], 1)\n",
    "        \n",
    "        # 2. Construct output feature\n",
    "        objectness = tf.ones_like(classes)\n",
    "        one_hot    = tf.one_hot(tf.cast(tf.squeeze(classes, axis=1), tf.uint8), num_classes)\n",
    "        values     = tf.concat([boxes, objectness, classes], axis=1)\n",
    "                \n",
    "         # 1. Determine indices (where to put gtruths in the feature map)\n",
    "        # two ground truths may be in same cell, \n",
    "        # so we need to calculate the IoU\n",
    "        iou_scores = iou(boxes, anchors_boxes)\n",
    "        cell_indices = tf.cast(tf.argmax(iou_scores, axis=1), tf.int32)\n",
    "        cell_indices = tf.expand_dims(cell_indices, axis=-1)\n",
    "        \n",
    "        area     = boxes[...,2:4] - boxes[..., 0:2]\n",
    "        centroid = boxes[..., 0:2] + (area / 2.0)    \n",
    "        indices  = tf.cast(tf.floor(centroid * (img_size / shrink_factor)), tf.int32)\n",
    "        indices   = tf.concat([indices, cell_indices], axis=-1)\n",
    "        \n",
    "\n",
    "        # 3. Create feature map\n",
    "        # https://www.tensorflow.org/api_docs/python/tf/scatter_nd\n",
    "        feature_map = tf.scatter_nd(indices, values, shape= [ 10, 10 ,5, 6])\n",
    "        \n",
    "        return img, feature_map\n",
    "\n",
    "    # a hack to handle list with different element size.\n",
    "    dataset = tf.data.Dataset.from_generator(lambda: itertools.izip_longest(images, labels),\n",
    "                                             (tf.string, tf.float32),\n",
    "                                             (tf.TensorShape([]), tf.TensorShape([None])))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=100)\n",
    "        \n",
    "    dataset = dataset.map(lambda filename, label:\n",
    "                          tuple(tf.py_func(read_img_file,\n",
    "                                           [filename, label],\n",
    "                                           [tf.uint8, label.dtype])))\n",
    "    dataset = dataset.map(process_label)\n",
    "\n",
    "    return dataset\n",
    "    \n",
    "val_gen = data_generator(x_val,  y_val,config['model']['image_size'], batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "images, values = val_gen.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w, _ = images.shape\n",
    "gt_boxes = gt_boxes * np.array([h, w, h, w]) \n",
    "\n",
    "frame = draw_boxes(images,  gt_boxes, [label_dict[i] for i in gt_classes], gt_classes)\n",
    "plt.figure(figsize=(10, 10))\n",
    "_ = plt.imshow(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx   = 0 \n",
    "image = images[idx]\n",
    "h,w, _ = image.shape\n",
    "gt_boxes   = labels[idx][..., 0:4]\n",
    "gt_classes = labels[idx][...,-1]\n",
    "\n",
    "print(gt_classes)\n",
    "print(gt_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    c =  tf.scatter_nd(tf.cast([[0, 0]], tf.int32), tf.cast([[1.0, 1.0]], tf.float32), shape=[3, 4, 2])\n",
    "\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(c.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bboxes = np.expand_dims(gt_boxes, 0)\n",
    "print bboxes\n",
    "\n",
    "a = np.squeeze(bboxes, 0)\n",
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
